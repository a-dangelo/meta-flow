FROM python:3.11-slim AS base

WORKDIR /app

ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1

# System deps for common Python packages (numpy, sentence-transformers)
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    git \
    curl \
 && rm -rf /var/lib/apt/lists/*

# Install project requirements (root + chatbot extras)
COPY requirements.txt /app/requirements.txt
COPY chatbot/requirements.txt /app/chatbot/requirements.txt
# Install CPU-only torch first to avoid pulling CUDA wheels
RUN pip install --no-cache-dir \
    torch==2.3.1 \
    --index-url https://download.pytorch.org/whl/cpu

# Install remaining dependencies
RUN pip install --no-cache-dir -r /app/requirements.txt \
 && pip install --no-cache-dir -r /app/chatbot/requirements.txt

# Pre-download embedding model to avoid runtime download and healthcheck failures
ENV HF_HOME=/root/.cache/huggingface \
    HF_HUB_CACHE=/root/.cache/huggingface \
    TRANSFORMERS_CACHE=/root/.cache/huggingface \
    SENTENCE_TRANSFORMERS_HOME=/root/.cache/huggingface

# Download model during build (with network access)
RUN python - <<'PY'
from sentence_transformers import SentenceTransformer
import os

# Ensure offline mode is disabled during build
os.environ.pop('HF_HUB_OFFLINE', None)

# This is the model used in chatbot/src/conversation/graph_hybrid.py
print("Downloading BAAI/bge-small-en-v1.5...")
model = SentenceTransformer("BAAI/bge-small-en-v1.5")
print(f"Model cached at: {model._model_card_text}")
PY

# Note: Removed HF_HUB_OFFLINE=1 to allow runtime downloads if needed
# This prevents FileNotFoundError when cache is missing

# Copy source
COPY . /app

ENV PYTHONPATH=/app

EXPOSE 8000

CMD ["uvicorn", "chatbot.api.main:app", "--host", "0.0.0.0", "--port", "8000"]
